{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkWXt2SNaR5ckzcr3NmRoA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AreebaAleem/Digital_Image_Processing/blob/main/Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFBy-zejj3F8",
        "outputId": "f8ba7ec8-8c4d-4000-d8d9-fca9fdd267d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.19.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (24.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python scikit-image scikit-learn keras\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from skimage.filters import gabor\n",
        "from keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "metadata": {
        "id": "bNUGnk0Bj7Di"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# List of your zip files\n",
        "zip_files = ['valid.zip', 'test.zip']\n",
        "\n",
        "# Extract each zip file\n",
        "for zip_file in zip_files:\n",
        "    try:\n",
        "        zip_path = f'/content/{zip_file}'\n",
        "        if os.path.exists(zip_path):\n",
        "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "                zip_ref.extractall('/content/')\n",
        "                print(f\"Extracted {zip_file} successfully!\")\n",
        "        else:\n",
        "            print(f\"{zip_file} not found. Please check the file name and path.\")\n",
        "    except zipfile.BadZipFile:\n",
        "        print(f\"Failed to extract {zip_file}. The file may be corrupted or too large.\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LY4Np_ijj9d9",
        "outputId": "02312d22-6f13-4912-e36d-0ad1eda2718f"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted valid.zip successfully!\n",
            "Extracted test.zip successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to your zip file\n",
        "zip_path = '/content/drive/My Drive/train.zip'\n",
        "\n",
        "# Extraction path\n",
        "extract_to = '/content/train/'\n",
        "\n",
        "# Create directory if it doesn't exist\n",
        "os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "print(\"Extraction Complete\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_eg0LNhkH6j",
        "outputId": "6c3c00ba-7ae8-444a-dcf9-ad85cfd2ac3b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Extraction Complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "def preprocess_image(image):\n",
        "    # Resize image\n",
        "    resized = cv2.resize(image, (64, 64))\n",
        "\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert to binary\n",
        "    _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Convert to YCrCb color space\n",
        "    ycrcb = cv2.cvtColor(resized, cv2.COLOR_BGR2YCrCb)\n",
        "\n",
        "    return gray  # Return the processed image\n",
        "\n",
        "    # Skin color range for YCrCb color space\n",
        "    lower_skin = np.array([0, 133, 77], dtype=np.uint8)\n",
        "    upper_skin = np.array([255, 173, 127], dtype=np.uint8)\n",
        "\n",
        "    # Apply a skin mask\n",
        "    skin_ycrcb = cv2.inRange(ycrcb, lower_skin, upper_skin)\n",
        "\n",
        "    # Apply edge detection\n",
        "    edges = cv2.Canny(skin_ycrcb, 100, 200)\n",
        "\n",
        "    # Apply segmentation\n",
        "    ret, segments = cv2.threshold(edges, 127, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Apply filtering\n",
        "    filtered = cv2.bilateralFilter(segments, 5, 75, 75)\n",
        "\n",
        "    # Hand region detection\n",
        "    contours, _ = cv2.findContours(filtered, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    areas = [cv2.contourArea(c) for c in contours]\n",
        "    if len(areas) > 0:\n",
        "        max_index = np.argmax(areas)\n",
        "        cnt = contours[max_index]\n",
        "        x, y, w, h = cv2.boundingRect(cnt)\n",
        "        hand_region = filtered[y:y+h, x:x+w]\n",
        "    else:\n",
        "        hand_region = filtered\n",
        "\n",
        "    # Background subtraction\n",
        "    fgbg = cv2.createBackgroundSubtractorMOG2()\n",
        "    fgmask = fgbg.apply(hand_region)\n",
        "\n",
        "    # Apply your sharpening filter here\n",
        "    # Your code here\n",
        "\n",
        "    return fgmask\n",
        "\n",
        "# Feature extraction\n",
        "def extract_features(image):\n",
        "    # Apply Gabor transformation\n",
        "    gabor_feat, _ = gabor(image, frequency=0.6)\n",
        "    return gabor_feat.flatten()\n",
        "\n"
      ],
      "metadata": {
        "id": "Xp3CdHXFkIcb"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def load_dataset(image_path, label_path):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    # Assuming label file that maps images to labels\n",
        "    label_file_path = os.path.join(label_path, \"labels.txt\")  # Update as per your label storage format\n",
        "    # Load labels\n",
        "    with open(label_file_path, \"r\") as file:\n",
        "        label_map = {line.split()[0]: int(line.split()[1]) for line in file.readlines()}\n",
        "\n",
        "    # Load images and map labels\n",
        "    for filename in os.listdir(image_path):\n",
        "        img = cv2.imread(os.path.join(image_path, filename))\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "            # Assuming image filename matches the label key\n",
        "            label = label_map.get(filename, -1)  # Default to -1 or any other flag value if label is missing\n",
        "            labels.append(label)\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "    images, labels = load_dataset(\"/content/train/train/images\", \"/content/train/train/labels\")\n",
        "\n",
        "\n",
        "\n",
        "def preprocess_image(image):\n",
        "    # Resize and convert to grayscale as an example\n",
        "    resized = cv2.resize(image, (64, 64))\n",
        "    gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
        "    return gray\n",
        "\n",
        "    processed_images = [preprocess_image(img) for img in images]\n",
        "\n",
        "\n",
        "    # Data augmentation\n",
        "    datagen = ImageDataGenerator(rotation_range=10, zoom_range=0.1, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "    augmented_images = datagen.flow(np.array(processed_images).reshape(len(processed_images), 64, 64, 1), np.array(labels))  # Ensure images are reshaped if needed\n",
        "\n",
        "    # Split dataset into training and testing\n",
        "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train a SVM classifier\n",
        "    clf = SVC(gamma='auto')\n",
        "    clf.fit(features_train, labels_train)\n",
        "\n",
        "    # Test the model\n",
        "    accuracy = clf.score(features_test, labels_test)\n",
        "    print(f\"Model accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "ngFAAN9BneRr"
      },
      "execution_count": 60,
      "outputs": []
    }
  ]
}